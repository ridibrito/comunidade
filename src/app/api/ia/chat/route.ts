import { NextRequest, NextResponse } from 'next/server';
import { GoogleGenerativeAI } from '@google/generative-ai';

// Verificar se a API key est√° configurada
if (!process.env.GEMINI_API_KEY) {
  console.error('GEMINI_API_KEY n√£o est√° configurada no .env.local');
}

const genAI = process.env.GEMINI_API_KEY 
  ? new GoogleGenerativeAI(process.env.GEMINI_API_KEY)
  : null;

export async function POST(request: NextRequest) {
  try {
    console.log('API de IA chamada');
    
    const { message, conversation, conversationId, userName } = await request.json();
    console.log('Mensagem recebida:', message);
    console.log('Conversa anterior:', conversation?.length || 0, 'mensagens');
    console.log('ID da conversa:', conversationId);

    if (!message) {
      console.log('Erro: Mensagem vazia');
      return NextResponse.json(
        { error: 'Mensagem √© obrigat√≥ria' },
        { status: 400 }
      );
    }

    if (!process.env.GEMINI_API_KEY) {
      console.log('Erro: GEMINI_API_KEY n√£o configurada');
      return NextResponse.json(
        { error: 'API key n√£o configurada' },
        { status: 500 }
      );
    }

    if (!genAI) {
      return NextResponse.json(
        { error: 'API Gemini n√£o inicializada' },
        { status: 500 }
      );
    }

    // Buscar prompt ativo
    let systemPrompt;
    try {
      const promptResponse = await fetch(`${process.env.NEXT_PUBLIC_APP_URL || 'http://localhost:3000'}/api/ia/prompt`);
      if (promptResponse.ok) {
        const promptData = await promptResponse.json();
        systemPrompt = promptData.content;
        // Adicionar instru√ß√£o sobre o nome do usu√°rio se dispon√≠vel
        if (userName) {
          systemPrompt += `\n\nVoc√™ est√° conversando com ${userName}. Use o nome dele(a) de forma natural e acolhedora nas suas respostas quando for apropriado.`;
        }
        console.log('Prompt ativo carregado:', promptData.name);
      } else {
        throw new Error('Erro ao carregar prompt');
      }
    } catch (error) {
      console.error('Erro ao carregar prompt ativo, usando padr√£o:', error);
      // Prompt padr√£o como fallback
      systemPrompt = `Voc√™ √© a Corujinha ü¶â, uma IA especializada em Altas Habilidades/Superdota√ß√£o (AHSD) e desenvolvimento infantil. 

Voc√™ √© uma mentora virtual experiente que trabalha com fam√≠lias, educadores e profissionais da √°rea. Suas caracter√≠sticas s√£o:

üéØ **Especializa√ß√£o**: AHSD, desenvolvimento infantil, educa√ß√£o especializada
üí° **Abordagem**: Pr√°tica, emp√°tica e baseada em evid√™ncias cient√≠ficas
ü§ù **Tom**: Acolhedor, profissional e encorajador
üìö **Conhecimento**: Estrat√©gias educacionais, desenvolvimento cognitivo, social e emocional

**Diretrizes para suas respostas:**
- Seja clara, objetiva e pr√°tica
- Ofere√ßa estrat√©gias espec√≠ficas e aplic√°veis
- Use linguagem acess√≠vel para pais e educadores
- Inclua exemplos pr√°ticos quando relevante
- Se n√£o souber algo espec√≠fico, seja honesta e sugira consulta com especialistas
- Mantenha o foco em AHSD e desenvolvimento infantil
- Seja emp√°tica com as dificuldades das fam√≠lias
- Sempre responda em portugu√™s brasileiro${userName ? `\n- Voc√™ est√° conversando com ${userName}, use o nome dele(a) quando for apropriado de forma natural e acolhedora` : ''}

Voc√™ est√° aqui para ajudar fam√≠lias com crian√ßas AHSD a navegar pelos desafios e oportunidades do desenvolvimento de altas habilidades.`;
    }

    // Preparar hist√≥rico de conversa para Gemini
    // O Gemini usa um formato diferente - precisa converter o hist√≥rico
    const history = conversation.map((msg: any) => ({
      role: msg.role === 'user' ? 'user' : 'model',
      parts: [{ text: msg.content }]
    }));

    // Criar o modelo
    const model = genAI.getGenerativeModel({ 
      model: 'gemini-pro',
      systemInstruction: systemPrompt
    });

    // Construir o chat com hist√≥rico
    const chat = model.startChat({
      history: history.length > 0 ? history : undefined,
    });

    console.log('Prompt do sistema:', systemPrompt.substring(0, 100) + '...');
    console.log('Total de mensagens no hist√≥rico:', history.length);

    const startTime = Date.now();
    const result = await chat.sendMessage(message);
    const responseTime = Date.now() - startTime;

    const response = result.response.text();
    console.log('Resposta do Gemini:', response);

    // Salvar mensagens na conversa se conversationId for fornecido
    if (conversationId) {
      try {
        // Salvar mensagem do usu√°rio
        await fetch(`${process.env.NEXT_PUBLIC_APP_URL || 'http://localhost:3000'}/api/ia/messages`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            conversationId,
            role: 'user',
            content: message
          })
        });

        // Salvar resposta da IA
        await fetch(`${process.env.NEXT_PUBLIC_APP_URL || 'http://localhost:3000'}/api/ia/messages`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            conversationId,
            role: 'assistant',
            content: response
          })
        });

        console.log('Mensagens salvas na conversa:', conversationId);
      } catch (error) {
        console.error('Erro ao salvar mensagens:', error);
      }
    }

    // Registrar intera√ß√£o no banco de dados
    try {
      const { createClient } = await import('@supabase/supabase-js');
      const supabase = createClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!
      );

      // Obter informa√ß√µes de uso do Gemini
      let tokensUsed = 0;
      try {
        const usageMetadata = (result.response as any).usageMetadata;
        tokensUsed = usageMetadata?.totalTokenCount || 0;
      } catch (error) {
        console.log('N√£o foi poss√≠vel obter informa√ß√µes de uso:', error);
      }

      const { data: interaction, error: interactionError } = await supabase
        .from('ia_interactions')
        .insert({
          user_message: message,
          ai_response: response,
          tokens_used: tokensUsed,
          response_time_ms: responseTime,
          cost_usd: 0, // Gemini tem pre√ßos diferentes, pode calcular depois
          success: true,
          metadata: {
            model: 'gemini-pro',
            temperature: 0.7,
            tokens: tokensUsed
          }
        })
        .select()
        .single();

      if (interactionError) {
        console.error('Erro ao registrar intera√ß√£o:', interactionError);
      } else {
        console.log('Intera√ß√£o registrada:', interaction.id);
      }
    } catch (error) {
      console.error('Erro ao registrar intera√ß√£o:', error);
    }

    return NextResponse.json({ response });

  } catch (error) {
    console.error('Erro na API de IA:', error);
    return NextResponse.json(
      { error: 'Erro interno do servidor', details: error instanceof Error ? error.message : 'Erro desconhecido' },
      { status: 500 }
    );
  }
}
